{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_from_lat_csv(data,latitude):\n",
    "\n",
    "    return data[data['latitude']==latitude]\n",
    "def min_value(data):\n",
    "    min_d=15582150000\n",
    "    for d in data:\n",
    "        if d<min_d:\n",
    "            min_d=d\n",
    "    return min_d\n",
    "def higher_value(data):\n",
    "    high=0\n",
    "    for d in data:\n",
    "        if d>high:\n",
    "            high=d\n",
    "    return high\n",
    "def return_list_means(list_bikes):\n",
    "\n",
    "    #\tprint(list_bikes[0:10])\n",
    "    memory=27\n",
    "    ponder=0.9\n",
    "    return_list=[]\n",
    "    sum=0\n",
    "    for m in range(0,memory):\n",
    "        sum+=list_bikes[m]\n",
    "        return_list.append(sum/(m+1)*ponder)\t\n",
    "    count=1\n",
    "    for i in range(memory,len(list_bikes)):\n",
    "        sum=0\n",
    "        for m in range(0,memory):\n",
    "            sum+=list_bikes[i-m]*(ponder/memory*(memory-m))\n",
    "\n",
    "        return_list.append(sum/memory)\t\t\n",
    "        count+=1\t\n",
    "    return return_list\n",
    "def convert_df_to_list(df):\n",
    "    return_list=[]\n",
    "    for d in df:\n",
    "        return_list.append(d)\n",
    "    return return_list\n",
    "def analize_point_data(data,point,bikes_column):\n",
    "    jump=900\n",
    "    previous=data[data.index[0]]\n",
    "\n",
    "    count_lost_tuples=0\n",
    "    for i in range(data.index[1],data.index[0]+len(data.index)):\n",
    "        if data[i]-previous!=jump:\n",
    "            count_lost_tuples+=int(((data[i]-previous)/jump)-1)\n",
    "\n",
    "            '''print((data[i-1]))\n",
    "            print((data[i]))\n",
    "            print(bikes_column[i-1])\n",
    "            print(bikes_column[i])'''\n",
    "            input()\n",
    "            print(i)\n",
    "            print((data[i]))\n",
    "            print(\"The difference is :\"+str(data[i]-previous))\n",
    "            print(str(int((data[i]-previous)/jump))+\" tuples lost\")\n",
    "\n",
    "            print(\"Which is :\"+str(dt.fromtimestamp(data[i])-dt.fromtimestamp(previous)))\n",
    "            print(str(count_lost_tuples)+\" lost tuples en total\")\n",
    "\n",
    "        previous=data[i]\n",
    "    print(str(count_lost_tuples-1)+\" lost tuples en total\")\n",
    "    print(str(count_lost_tuples/4)+\" hour of lost data in point \"+str(point))\n",
    "\n",
    "    return count_lost_tuples-1\n",
    "\n",
    "def generate_real_timestamp_bikes_list(data,timestamp_start=1544095800,timestamp_end=1558215900):\n",
    "    return_list=[]\n",
    "    timestamp_from_list=convert_df_to_list(data.timestamp_from)\n",
    "    bikes_list=convert_df_to_list(data.bike_count)\n",
    "    num_expected_rows=(timestamp_end-timestamp_start)/900\n",
    "    for i in range(0,int(num_expected_rows)):\n",
    "        if int(timestamp_start+(i*900)) in timestamp_from_list:\n",
    "\n",
    "            #print(timestamp_from_list.index(int(timestamp_start+(i*900))))\n",
    "            return_list.append(bikes_list[timestamp_from_list.index(int(timestamp_start+(i*900)))])\n",
    "        else:\n",
    "            return_list.append(0)\n",
    "\n",
    "\n",
    "    return return_list\n",
    "def show_data_real_timestamp_bikes_list(data,time_start,time_end):\n",
    "    result_list=generate_real_timestamp_bikes_list(data,time_start,time_end)\n",
    "    list_vals=return_list_means(result_list)\n",
    "    '''print((result_list[0:24]))\n",
    "    print((list_vals[0:24]))\n",
    "\n",
    "    input()'''\n",
    "    days=28\n",
    "    for i in range(0,int(len(result_list)/(96*days))):\n",
    "\n",
    "        plt.plot(result_list[i*96*days:i*96*days+96*days], 'g', alpha=0.7)\n",
    "        plt.plot(list_vals[i*96*days:i*96*days+96*days], 'r')\n",
    "        plt.legend(['Bike count', 'Trend'])\n",
    "        plt.ylim(0,200)\n",
    "        figManager = plt.get_current_fig_manager()\n",
    "        figManager.full_screen_toggle() \n",
    "        plt.show()\n",
    "\n",
    "    plt.plot(result_list,'g',alpha=0.7)\n",
    "    plt.plot(list_vals,'r')\n",
    "    plt.legend(['Bike count', 'Trend'])\n",
    "    plt.ylim(0,200)\n",
    "    figManager = plt.get_current_fig_manager()\n",
    "    figManager.full_screen_toggle() \n",
    "    plt.show()\n",
    "def obtain_latitudes_list(latitude_data):\t\n",
    "    return latitude_data.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all_points=pd.read_csv(\".././data/combined_data.tsv\", delimiter=\"\\t\",header=0)\n",
    "latitudes_list=obtain_latitudes_list(dataset_all_points.latitude)\n",
    "timestamp_highest_value\t=higher_value(dataset_all_points['timestamp_from'])\n",
    "timestamp_lowest_value=min_value(dataset_all_points['timestamp_from'])\n",
    "all_data_we_have=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_graph=28\n",
    "for latitude in latitudes_list:\n",
    "    dataset=select_data_from_lat_csv(dataset_all_points,latitude)\n",
    "    print(\"Pole data on point \"+str(latitude))   \n",
    "    y=dataset['bike_count']\n",
    "    all_data_we_have+=y.shape[0]\n",
    "    print(str(y.shape[0])+\" tuples\")\n",
    "    print(\"Must be :\"+str(int((timestamp_highest_value-timestamp_lowest_value)/900)))\n",
    "    print(\"we lost \"+str((int((timestamp_highest_value-timestamp_lowest_value)/900)-y.shape[0])/4)+\" HOURS OF DATA\")\n",
    "    print(\"We have \"+str((y.shape[0]*100/((timestamp_highest_value-timestamp_lowest_value)/900)))+\" % of data.\")\n",
    "    if (y.shape[0]*100/((timestamp_highest_value-timestamp_lowest_value)/900))!=0.0:\n",
    "        print(\"Press ENTER to show the figure...\")\n",
    "        #input()\n",
    "        show_data_real_timestamp_bikes_list(dataset,timestamp_lowest_value,timestamp_highest_value)\n",
    "    else:\n",
    "        print(\"we don't show the data because is 0.0 %. Press ENTER...\")\n",
    "        #input()\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    #print(y[0:10])\n",
    "\n",
    "print(str(all_data_we_have*100/(int((timestamp_highest_value-timestamp_lowest_value)/900)*9))+\" % total data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
